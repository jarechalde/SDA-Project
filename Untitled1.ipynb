{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#V2.0 Del proyecto\n",
    "\n",
    "#Project\n",
    "\n",
    "#First we start spark\n",
    "import pyspark\n",
    "import os\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Load the packages before creating the context\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.4.1 pyspark-shell'\n",
    "\n",
    "#Initializing the Spark Context\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "\n",
    "#Initialize the SQL context\n",
    "sql = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  3187\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "NO LOCATION DATA\n",
      "[['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['32', '53'], ['33', '65'], ['33', '65'], ['32', '53'], ['32', '53'], ['32', '53'], ['48.2', '16.3667'], ['48.2', '16.3667'], ['48.2', '16.3667'], ['45.6333', '5.73333'], ['45.6333', '5.73333'], ['45.6333', '5.73333'], ['45.6333', '5.73333'], ['32', '53'], ['47.3333', '13.3333']]\n"
     ]
    }
   ],
   "source": [
    "#Lets load a sample of the data \n",
    "mydata = sql.read.format(\"csv\").options(delimiter='\\t').load(\"C:/Users/jarec/OneDrive/Umass Dartmouth/Scalable Data Analysis/Project/20151214160000.gkg.csv\")\n",
    "\n",
    "#We will probably have to construct a header to name all the columns\n",
    "\n",
    "#Renaming the columns\n",
    "mydata = mydata.toDF(\"GKGRECORDID\",\n",
    "          \"V2.1 DATE\",\n",
    "          \"V2SOURCECOLLECTIONIDENTIFIER\",\n",
    "          \"V2SOURCECOMMONNAME\",\n",
    "          \"V2DOCUMENTIDENTIFIER\",\n",
    "          \"V1COUNTS\",\n",
    "          \"V2.1COUNTS\",\n",
    "          \"V1THEMES\",\n",
    "          \"V2ENHANCEDTHEMES\",\n",
    "          \"V1LOCATIONS\",\n",
    "          \"V2ENHANCEDLOCATIONS\",\n",
    "          \"V1PERSONS\",\n",
    "          \"V2ENHANCEDPERSONS\",\n",
    "          \"V1ORGANIZATIONS\",\n",
    "          \"V2ENHANCEDORGANIZATIONS\",\n",
    "          \"V1.5TONE\",\n",
    "          \"V2.1ENHANCEDDATES\",\n",
    "          \"V2GCAM\",\n",
    "          \"V2.1SHARINGIMAGE\",\n",
    "          \"V2.1RELATEDIMAGES\",\n",
    "          \"V2.1SOCIALIMAGEEMBEDS\",\n",
    "          \"V2.1SOCIALVIDEOEMBEDS\",\n",
    "          \"V2.1QUOTATIONS\",\n",
    "          \"V2.1ALLNAMES\",\n",
    "          \"V2.1AMOUNTS\",\n",
    "          \"V2.1TRANSLATIONINFO\",\n",
    "          \"V2EXTRASXML\")\n",
    "\n",
    "#Number of rows we have\n",
    "nrows = mydata.count()\n",
    "\n",
    "print(\"Number of rows: \",nrows)\n",
    "\n",
    "#Collect data so we can treat it as a list\n",
    "mydata = mydata.collect()\n",
    "\n",
    "#Initializing the location list\n",
    "loclists = []\n",
    "\n",
    "#Change the limit to nrows later\n",
    "for i in range(1,50):\n",
    " \n",
    "    loc = mydata[i][\"V2ENHANCEDLOCATIONS\"]\n",
    "        \n",
    "    #If locations null we should skip this part\n",
    "    \n",
    "    if loc==None:\n",
    "        print(\"NO LOCATION DATA\")\n",
    "        continue\n",
    "    \n",
    "    #If the locations exist, we continue saving the place\n",
    "    locations = loc.split(\";\")\n",
    "    latlist = []\n",
    "    \n",
    "    for location in locations:\n",
    "        locatt = location.split(\"#\")\n",
    "        lat = locatt[5]\n",
    "        long = locatt[6]\n",
    "        latlong = [lat,long]\n",
    "        latlist.append(latlong)\n",
    "        #We should save in the third part of the list the number of times same location appeared to set a circle size in the map\n",
    "    \n",
    "    \n",
    "    loclists.append(latlist)\n",
    "    \n",
    "print(loclists[1][:])\n",
    "\n",
    "#Depending on the number of locations for each new we should create a different GEOJSON, point, polygon, etc.\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
